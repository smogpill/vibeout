// Vibeout (https://github.com/smogpill/vibeout)
// SPDX-FileCopyrightText: 2025 Jounayd ID SALAH
// SPDX-License-Identifier: MIT
#version 460
#extension GL_GOOGLE_include_directive : enable 
#extension GL_EXT_nonuniform_qualifier : enable

#define GLOBAL_UBO_DESC_SET_IDX 0
#include "GlobalUBO.h"

#define GLOBAL_TEXTURES_DESC_SET_IDX 1
#include "GlobalTextures.h"

#define GLOBAL_STORAGE_DESC_SET_IDX 3
#include "GlobalStorage.h"

void main() {}

#if 0

#include "Lighting.glsl"
#include "Geometry.glsl"
#include "Compression.glsl"
#include "DistanceField.glsl"
#include "Encoding.glsl"
#include "Interpolation.glsl"
#include "Noise.glsl"
#include "RayTrace.glsl"
#include "PTRayGen.h"
#include "Projection.glsl"

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;

const float maxDist = 1000.0f;

void generate_rng_seed(ivec2 ipos, bool is_odd_checkerboard)
{
	int frame_num = _globalUBO._currentFrameIdx;

	uint frame_offset = frame_num / NUM_BLUE_NOISE_TEX;

	rng_seed = 0;
	rng_seed |= (uint(ipos.x + frame_offset) % BLUE_NOISE_RES) << RNG_SEED_SHIFT_X;
	rng_seed |= (uint(ipos.y + (frame_offset << 4)) % BLUE_NOISE_RES) << RNG_SEED_SHIFT_Y;
	rng_seed |= uint(is_odd_checkerboard) << RNG_SEED_SHIFT_ISODD;
	rng_seed |= uint(frame_num) << RNG_SEED_SHIFT_FRAME;

	imageStore(IMG_ASVGF_RNG_SEED_A, ipos, uvec4(rng_seed));
}

Ray computeCameraRay(in vec2 pixelScreenCoords)
{
	vec4 pixel_s0 = vec4(pixelScreenCoords.x, pixelScreenCoords.y, 0, 1);
	vec4 pixel_s1 = vec4(pixelScreenCoords.x, pixelScreenCoords.y, 1, 1);

	const vec4 pixel_w0h = _globalUBO._invProj * pixel_s0;
	const vec4 pixel_w1h = _globalUBO._invProj * pixel_s1;

	vec3 pixel_w0 = pixel_w0h.xyz / pixel_w0h.w;
	vec3 pixel_w1 = pixel_w1h.xyz / pixel_w1h.w;

	Ray r;
	r.o = vec3(0, 0, 0);
	r.d = normalize(pixel_w1 - pixel_w0);

	vec3 o_prime = vec3(_globalUBO._invView * vec4(r.o, 1));
	vec3 e_prime = vec3(_globalUBO._invView * vec4(r.d, 1));
	r.o = o_prime;
	r.d = normalize(e_prime - o_prime);
	return r;
}

Ray get_primary_ray(vec2 screen_pos)
{
	vec3 view_dir = projection_screen_to_view(screen_pos, 1, false);
	view_dir = normalize((_globalUBO._invView * vec4(view_dir, 0)).xyz);

	Ray ray;
	ray.o = vec3(0);
	ray.d = view_dir;
	ray.o += _globalUBO._camPos.xyz;

	return ray;
}

void main()
{
	ivec2 ipos = ivec2(gl_GlobalInvocationID.xy);
	const int halfWidth = _globalUBO._width / 2;
	if(any(greaterThanEqual(ipos, ivec2(halfWidth, _globalUBO._height))))
		return;
	bool is_odd_checkerboard = gl_GlobalInvocationID.z != 0;
	if (is_odd_checkerboard)
		ipos.x += halfWidth;
	ivec2 resolution = ivec2(_globalUBO._width, _globalUBO._height);

	generate_rng_seed(ipos, is_odd_checkerboard);

	vec2 pixel_offset = _globalUBO.sub_pixel_jitter;
	
	vec2 sampleInPixel = ipos; //+ ComputePixelOffset(rngState)
    vec2 screenCoords = (sampleInPixel / resolution) * 2.0 - 1.0;

	const ivec2 image_position = get_image_position();
	const vec2 pixel_center = vec2(image_position) + vec2(0.5);
	const vec2 inUV = (pixel_center + pixel_offset) / vec2(get_image_size());

	//Ray r = computeCameraRay(screenCoords);
	Ray r = get_primary_ray(inUV);
	const vec3 direction = r.d;
	//r.o += vec3(RandomFloat01(rngState), RandomFloat01(rngState), RandomFloat01(rngState)) * 0.001f;
	r.d *= maxDist;

	vec3 hitNormal;
	vec4 result = CastGlobal(r, _globalUBO._drawVoxelLevel, hitNormal);

	if (result.x < 0)
	{
		hitNormal = vec3(0.0f);
		result.x = 1.0f;

		//vec4 transparent = alpha_blend(effects, vec4(env, 1));
		vec4 transparent = vec4(0, 0, 0, 1);

		// Compute a motion vector for the sky, because we don't want TAA to blur it
		vec3 prev_view_dir = (_globalUBO._prevView * vec4(direction, 0)).xyz;
		vec2 prev_screen_pos;
		float prev_distance;
		projection_view_to_screen(prev_view_dir, prev_screen_pos, prev_distance, true);
		vec2 motion = prev_screen_pos - inUV;

		// Store an empty surface into the G-buffer
		imageStore(IMG_PT_NORMAL_A, ipos, uvec4(0));
		imageStore(IMG_PT_GEO_NORMAL_A, ipos, uvec4(0));
		imageStore(IMG_PT_VIEW_DEPTH_A, ipos, vec4(maxTraceDist));
		imageStore(IMG_PT_GODRAYS_THROUGHPUT_DIST, ipos, vec4(1, 1, 1, maxTraceDist));
		imageStore(IMG_PT_VIEW_DIRECTION, ipos, vec4(direction, 0));
		imageStore(IMG_PT_SHADING_POSITION, ipos, vec4(_globalUBO._camPos.xyz + direction * maxTraceDist, 0));
		imageStore(IMG_PT_MOTION, ipos, vec4(motion, 0, 0));
		imageStore(IMG_PT_VISBUF_PRIM_A, ipos, uvec4(0));
		imageStore(IMG_PT_VISBUF_BARY_A, ipos, vec4(0));
		imageStore(IMG_PT_BASE_COLOR_A, ipos, vec4(0));
		imageStore(IMG_PT_TRANSPARENT, ipos, transparent);
		return;
	}

	int checkerboard_flags = CHECKERBOARD_FLAG_PRIMARY;
	uint materialID = 1;
	vec3 primary_base_color = vec3(1, 1, 1);
	vec3 primary_emissive = vec3(0);
	float primary_specular_factor = 0.0f;
	float primary_metallic = 0.0f;
	float primary_roughness = 1.0f;
	
	const float hitDist = result.x * maxDist;

	// Hack
	primary_base_color = vec3(0.8);

	vec3 throughput = vec3(1);

	if (hitNormal.z < -0.9f)
	{
		primary_base_color = vec3(0.9f, 0.15f, 0.3f);
		primary_emissive = vec3(1) * _globalUBO._fakeEmissive;
		//break;
	}
		
	throughput *= primary_base_color;

	if (result.x >= 1.0f)
		throughput = vec3(0.0f);

	vec3 hitPos = r.o + r.d * result.x;

	// Compute view-space derivatives of depth and motion vectors
	//Ray ray_0 = r;
	Ray ray_x = get_primary_ray(inUV + vec2(1.0 / float(_globalUBO._width), 0));
	Ray ray_y = get_primary_ray(inUV + vec2(0, 1.0 / float(_globalUBO._height)));

	float half_cone_angle = sqrt(max(0.0, 1.0 - square(min(dot(direction, ray_x.d), dot(direction, ray_y.d))))); // Max is for safety

	float fwidth_depth = 0.0f;

	//compute_anisotropic_texture_gradients(position, flat_normal, ray.direction, 
	//	hitDist * half_cone_angle, triangle.positions, 
	//	triangle.tex_coords, tex_coord, tex_coord_x, tex_coord_y, fwidth_depth);

	vec3 pos_ws_curr = hitPos;
	//vec3 pos_ws_prev = triangle.positions_prev * bary;
	vec3 pos_ws_prev = pos_ws_curr;
	
	vec2 screen_pos_curr, screen_pos_prev;
	float distance_curr, distance_prev;
	projection_view_to_screen((_globalUBO._view * vec4(pos_ws_curr, 1)).xyz, screen_pos_curr, distance_curr, false);
	projection_view_to_screen((_globalUBO._prevView * vec4(pos_ws_prev, 1)).xyz, screen_pos_prev, distance_prev, true);
	
	vec3 motion;
	motion.xy = screen_pos_prev - screen_pos_curr;
	motion.z = distance_prev - distance_curr;

	imageStore(IMG_PT_VIEW_DEPTH_A, ipos, vec4(distance_curr));
	imageStore(IMG_PT_MOTION, ipos, vec4(motion, fwidth_depth));
	imageStore(IMG_PT_NORMAL_A, ipos, uvec4(encode_normal(hitNormal)));
	imageStore(IMG_PT_GEO_NORMAL_A, ipos, uvec4(encode_normal(hitNormal)));
	imageStore(IMG_PT_SHADING_POSITION, ipos, vec4(hitPos.xyz, uintBitsToFloat(materialID)));
	imageStore(IMG_PT_VIEW_DIRECTION, ipos, vec4(direction, float(checkerboard_flags)));
	imageStore(IMG_PT_THROUGHPUT, ipos, vec4(throughput, distance_curr));
	imageStore(IMG_PT_BOUNCE_THROUGHPUT, ipos, vec4(1, 1, 1, half_cone_angle));
	//imageStore(IMG_PT_CLUSTER_A, ipos, ivec4(triangle.cluster));
	imageStore(IMG_PT_BASE_COLOR_A, ipos, vec4(primary_base_color, primary_specular_factor));
	imageStore(IMG_PT_METALLIC_A, ipos, vec4(primary_metallic, primary_roughness, 0, 0));
	imageStore(IMG_PT_GODRAYS_THROUGHPUT_DIST, ipos, vec4(1, 1, 1, distance_curr));

	// Start the transparency accumulation from the primary surface emissive component, with zero alpha
	vec4 transparent = vec4(primary_emissive * throughput, 0);
	imageStore(IMG_PT_TRANSPARENT, ipos, transparent);

	// Fill the depth buffer
    //vec4 eyeSpacePos = inverse(invView) * vec4(hitPos, 1);
    //vec4 projP = inverse(invProj) * eyeSpacePos;
	//float depth = projP.z / projP.w; // perspective divide
}

#endif